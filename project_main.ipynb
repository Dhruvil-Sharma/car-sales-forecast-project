{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5593617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ad004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1. Load the raw data\n",
    "df = pd.read_csv('FS-data-80475.csv')\n",
    "\n",
    "# 2. Impute Missing KPI Names (Handles Nulls)\n",
    "print(f\"Rows with missing 'english_name' before: {df['english_name'].isnull().sum()}\")\n",
    "lookup_map = df.dropna(subset=['account_id', 'english_name']) \\\n",
    "               .drop_duplicates(subset=['account_id']) \\\n",
    "               .set_index('account_id')['english_name'] \\\n",
    "               .to_dict()\n",
    "df['english_name'] = df['english_name'].fillna(df['account_id'].map(lookup_map))\n",
    "df.dropna(subset=['english_name'], inplace=True)\n",
    "print(f\"Rows with missing 'english_name' after imputing: {df['english_name'].isnull().sum()}\")\n",
    "\n",
    "# 3. Clean and Standardize All KPI Names (Fixes Duplicates & Special Chars)\n",
    "def clean_kpi_name(name):\n",
    "    name = re.sub(r'[\\(\\)\\[\\]\\{\\}\\n]', '', name) # Remove special characters\n",
    "    name = re.sub(r'\\s+', ' ', name)            # Replace multiple spaces with one\n",
    "    name = name.strip()                         # Remove leading/trailing whitespace\n",
    "    return name\n",
    "df['english_name'] = df['english_name'].apply(clean_kpi_name)\n",
    "print(\"\\nKPI names have been cleaned and standardized.\") \n",
    "\n",
    "# 4. Create a Datetime Index\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01')\n",
    "\n",
    "# 5. Pivot the Data (Now with Clean Columns)\n",
    "time_series_df = df.pivot_table(\n",
    "    index='date',\n",
    "    columns='english_name',\n",
    "    values='monthly_value',\n",
    "    aggfunc='sum' # Use 'sum' to combine values from cleaned duplicate names\n",
    ")\n",
    "\n",
    "# --- NEW STEP: Remove Columns Containing Only Zeros ---\n",
    "print(f\"\\nOriginal number of KPIs (columns): {time_series_df.shape[1]}\")\n",
    "\n",
    "# Identify columns where ALL values are zero\n",
    "cols_to_remove = time_series_df.columns[(time_series_df == 0).all()]\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "time_series_df = time_series_df.drop(columns=cols_to_remove)\n",
    "\n",
    "print(f\"Removed {len(cols_to_remove)} columns that only contained zeros.\")\n",
    "print(f\"New final number of KPIs (columns): {time_series_df.shape[1]}\")\n",
    "# --- END OF NEW STEP ---\n",
    "\n",
    "\n",
    "# 6. Save the final cleaned dataset to your system\n",
    "cleaned_file_path = 'cleaned_model_ready_data.csv'\n",
    "time_series_df.to_csv(cleaned_file_path)\n",
    "\n",
    "print(f\"\\n✅ Cleaned data (with all-zero columns removed) has been saved to '{cleaned_file_path}'\")\n",
    "print(\"✅ Data is now ready for model training.\")\n",
    "time_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a927401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the KPI you want to forecast. Let's use 'TOTAL NEW VEHICLE DEPT'.\n",
    "kpi_to_forecast = 'TOTAL NEW VEHICLE DEPT'\n",
    "\n",
    "# Get the data for just this KPI from your cleaned DataFrame.\n",
    "# .fillna(0) is a simple way to handle any missing months for this KPI.\n",
    "kpi_series = time_series_df[kpi_to_forecast].fillna(0)\n",
    "\n",
    "# Plot the historical data to see the pattern\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(kpi_series)\n",
    "plt.title(f'Historical Monthly Values for {kpi_to_forecast}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Monthly Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b63c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrected Forecasting Loop for All KPIs ---\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create an empty DataFrame to store all our forecasts\n",
    "all_forecasts = pd.DataFrame()\n",
    "kpi_columns = time_series_df.columns\n",
    "print(f\"Starting forecast for {len(kpi_columns)} KPIs...\")\n",
    "\n",
    "# Loop through each KPI column\n",
    "for kpi in kpi_columns:\n",
    "    kpi_series = time_series_df[kpi].fillna(0)\n",
    "    \n",
    "    try:\n",
    "        model = sm.tsa.statespace.SARIMAX(kpi_series,\n",
    "                                        order=(1, 1, 1),\n",
    "                                        seasonal_order=(1, 1, 1, 12))\n",
    "        results = model.fit(disp=False)\n",
    "        \n",
    "        # This is the corrected part that gets 3 months\n",
    "        forecast = results.get_forecast(steps=3)\n",
    "        predicted_values = forecast.predicted_mean\n",
    "        \n",
    "        all_forecasts[kpi] = predicted_values\n",
    "        \n",
    "    except Exception as e:\n",
    "        all_forecasts[kpi] = [0, 0, 0]\n",
    "\n",
    "print(\"\\n\\n✅ All KPIs have been forecasted for 3 months!\")\n",
    "\n",
    "# Save the final forecast results\n",
    "forecast_file_path = '3_month_forecast_all_kpis.csv'\n",
    "all_forecasts.to_csv(forecast_file_path)\n",
    "print(f\"✅ Forecast has been saved to '{forecast_file_path}'\")\n",
    "\n",
    "# Display the final forecast to confirm it has 3 rows\n",
    "all_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a47e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Forecasted Values for Jan, Feb, Mar 2025 ---\")\n",
    "all_forecasts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = time_series_df.corr()\n",
    "\n",
    "print(\"✅ Correlation matrix calculated successfully.\")\n",
    "\n",
    "# Display the top 5 rows and columns of the matrix\n",
    "correlation_matrix.head()\n",
    "\n",
    "# forecast_file_path = '3_month_forecast_all_kpis.csv'\n",
    "\n",
    "# # Use the .to_csv() function to save the DataFrame\n",
    "# all_forecasts.to_csv(forecast_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create the heatmap using seaborn\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm') # 'coolwarm' is a good color map for correlations\n",
    "\n",
    "plt.title('Correlation Matrix of All KPIs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a file path for your correlation matrix\n",
    "correlation_file_path = 'cleaned_correlation_matrix.csv'\n",
    "\n",
    "# Use the .to_csv() function to save the DataFrame\n",
    "correlation_matrix.to_csv(correlation_file_path)\n",
    "\n",
    "print(f\"✅ Successfully saved the correlation matrix to: {correlation_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- FINAL STEP: Model Accuracy Calculation using Train-Test Split ---\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from tqdm import tqdm # A library to show a progress bar\n",
    "\n",
    "# # 1. LOAD YOUR FINAL CLEANED DATA\n",
    "# time_series_df = pd.read_csv('cleaned_model_ready_data.csv', index_col='date', parse_dates=True)\n",
    "\n",
    "# # 2. CHRONOLOGICAL TRAIN-TEST SPLIT\n",
    "# print(\"--- Splitting data into Training and Testing sets ---\")\n",
    "# cutoff_date = '2024-01-01'\n",
    "# train_data = time_series_df[time_series_df.index < cutoff_date]\n",
    "# test_data = time_series_df[time_series_df.index >= cutoff_date]\n",
    "# print(f\"Training data: {train_data.shape[0]} months, Testing data: {test_data.shape[0]} months\")\n",
    "\n",
    "# # 3. TRAIN ON TRAIN SET, FORECAST FOR TEST SET DURATION\n",
    "# print(\"\\n--- Training models and forecasting to get accuracy score... ---\")\n",
    "# # This may take a few minutes to run.\n",
    "# forecasts = pd.DataFrame()\n",
    "# for kpi in tqdm(train_data.columns, desc=\"Forecasting KPIs\"):\n",
    "#     train_series = train_data[kpi].fillna(0)\n",
    "#     try:\n",
    "#         model = sm.tsa.statespace.SARIMAX(train_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "#         results = model.fit(disp=False)\n",
    "#         prediction = results.get_forecast(steps=len(test_data))\n",
    "#         forecasts[kpi] = prediction.predicted_mean\n",
    "#     except Exception as e:\n",
    "#         forecasts[kpi] = [0] * len(test_data)\n",
    "\n",
    "# # 4. CALCULATE ACCURACY (MAPE)\n",
    "# print(\"\\n--- Calculating final model accuracy ---\")\n",
    "# actuals = test_data[forecasts.columns]\n",
    "# percentage_error = np.abs((actuals - forecasts) / actuals) * 100\n",
    "# percentage_error.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# mape = np.nanmean(percentage_error.values)\n",
    "\n",
    "# # 5. DISPLAY THE FINAL RESULT\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(f\"✅ The Model's Mean Absolute Percentage Error (MAPE) is: {mape:.2f}%\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- FINAL ACCURACY: Calculate MAPE on Top 10 KPIs ---\n",
    "\n",
    "# # 1. Find the 10 KPIs with the highest average historical value\n",
    "# top_10_kpis = time_series_df.mean().nlargest(10).index.tolist()\n",
    "\n",
    "# print(\"--- Calculating a more meaningful MAPE on the Top 10 KPIs ---\")\n",
    "# print(\"Top 10 KPIs by average value:\")\n",
    "# for kpi in top_10_kpis:\n",
    "#     print(f\"  - {kpi}\")\n",
    "\n",
    "# # 2. Filter your actuals and forecasts to only include these top KPIs\n",
    "# actuals_top_10 = test_data[top_10_kpis]\n",
    "# forecasts_top_10 = forecasts[top_10_kpis]\n",
    "\n",
    "# # 3. Recalculate the MAPE\n",
    "# percentage_error_top_10 = np.abs((actuals_top_10 - forecasts_top_10) / actuals_top_10) * 100\n",
    "# percentage_error_top_10.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# mape_top_10 = np.nanmean(percentage_error_top_10.values)\n",
    "\n",
    "# # 4. DISPLAY THE FINAL, MEANINGFUL RESULT\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(f\"✅ The MAPE for the Top 10 most significant KPIs is: {mape_top_10:.2f}%\")\n",
    "# print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
